{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-06 23:27:45.179901: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-06 23:27:45.347041: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-06 23:27:45.347056: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-06 23:27:46.075115: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-06 23:27:46.075169: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-06 23:27:46.075176: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Normalization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(model_shape):\n",
    "    # print(model_shape)\n",
    "    # print(model_shape.shape[1])\n",
    "    # normal = Normalization(input_shape=[model_shape.shape[1],], axis=None)\n",
    "    # normal.adapt(model_shape)\n",
    "    model = Sequential()\n",
    "    # model.add(normal)\n",
    "    # model.add(Dense(units=4, activation=\"relu\"))\n",
    "    # model.add(Dense(units=8, activation=\"relu\"))\n",
    "    # model.add(Dense(units=16, activation=\"relu\"))\n",
    "    # model.add(Dense(units=32, activation=\"relu\"))\n",
    "    # model.add(Dense(units=64, activation=\"relu\"))\n",
    "    # model.add(Dense(units=128, activation=\"relu\"))\n",
    "    model.add(Dense(units=256, activation=\"relu\", input_shape=[model_shape.shape[1],]))\n",
    "    model.add(Dense(units=256, activation=\"relu\"))\n",
    "    model.add(Dense(units=256, activation=\"relu\"))\n",
    "    model.add(Dense(units=128, activation=\"relu\"))\n",
    "    model.add(Dense(units=128, activation=\"relu\"))\n",
    "    model.add(Dense(units=128, activation=\"relu\"))\n",
    "    model.add(Dense(units=64, activation=\"relu\"))\n",
    "    model.add(Dense(units=64, activation=\"relu\"))\n",
    "    model.add(Dense(units=64, activation=\"relu\"))\n",
    "    model.add(Dense(units=1, activation=\"relu\"))\n",
    "    # model.add(Dense(units=1000000, activation=\"relu\"))\n",
    "    # model.add(Dense(units=10, activation=\"relu\"))\n",
    "    # RED WINE\n",
    "    # model.add(Dense(units=4, input_shape=(model_shape.shape[1],), activation=\"relu\"))\n",
    "    # model.add(Dense(units=8, activation=\"relu\"))\n",
    "    # model.add(Dense(units=16, activation=\"relu\"))\n",
    "    # model.add(Dense(units=32, activation=\"relu\"))\n",
    "    # model.add(Dense(units=64, activation=\"relu\"))\n",
    "    # model.add(Dense(units=128, activation=\"relu\"))\n",
    "    # model.add(Dense(units=98, activation=\"relu\"))\n",
    "    # model.add(Dense(units=46, activation=\"relu\"))\n",
    "    # model.add(Dense(units=32, activation=\"relu\"))\n",
    "    # model.add(Dense(units=12, activation=\"relu\"))\n",
    "    # model.add(Dense(units=10, activation=\"relu\"))\n",
    "    model.compile(optimizer=\"adam\", metrics=['mae', 'mse'], loss='mse')\n",
    "    #model.compile(optimizer=\"adam\", metrics=['accuracy'], loss='binary_crossentropy')\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_purge_data():\n",
    "    raw_data = pd.read_csv(\"vehicles.csv\")\n",
    "    #picked_columns = raw_data[[\"price\", \"year\", \"manufacturer\", \"model\", \"odometer\", \"drive\"]]\n",
    "    picked_columns = raw_data[[\"price\", \"year\", \"odometer\"]]\n",
    "    data_without_nulls = picked_columns.dropna(axis=0)\n",
    "    print(data_without_nulls.isnull().sum())\n",
    "    return data_without_nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, valid_col):\n",
    "    size = len(data.index)\n",
    "    p7 = int((70 * size) / 100)\n",
    "    p2 = int((20 * size) / 100)\n",
    "    p1 = int((10 * size) / 100)\n",
    "    v_col = data[[valid_col]]\n",
    "    data = data.drop(valid_col, axis=1)\n",
    "    part1 = data[1 : p7]\n",
    "    part2 = data[p7 : p7+p2]\n",
    "    part3 = data[p7+p2 : p7+p2+p1]\n",
    "    part1_v_col = v_col[1 : p7]\n",
    "    part2_v_col = v_col[p7 : p7+p2]\n",
    "    part3_v_col = v_col[p7+p2 : p7+p2+p1]\n",
    "    return part1, part2, part3, part1_v_col, part2_v_col, part3_v_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def data_splitter(data_x, data_y):\n",
    "    return train_test_split(data_x, data_y, test_size=0.3, random_state=101)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def red_wine_load():\n",
    "    wine_raw_data = pd.read_csv(\"winequality-red.csv\")\n",
    "    rw_x = wine_raw_data.drop('quality', axis=1)\n",
    "    rw_y = wine_raw_data['quality']\n",
    "    rw_x_train, rw_x_test, rw_y_train, rw_y_test = train_test_split(rw_x, rw_y, test_size=0.3, random_state=101)\n",
    "    return rw_x_train, rw_x_test, rw_y_train, rw_y_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# RED WINE\n",
    "# w_x_train, w_x_test, w_y_train, w_y_test = red_wine_load()\n",
    "# w_r_data = pd.read_csv(\"winequality-red.csv\")\n",
    "# w_x_train, w_x_test, w_x_val, w_y_train, w_y_test, w_y_val = split_data(w_r_data, \"quality\")\n",
    "# mdl = make_model(w_x_train)\n",
    "# history = mdl.fit(w_x_train, w_y_train, batch_size=32, epochs=100, validation_data=(w_x_test, w_y_test))\n",
    "# results = mdl.evaluate(w_x_val, w_y_val, batch_size=128)\n",
    "# print(\"test loss, test acc:\", results)\n",
    "\n",
    "# CARS\n",
    "# x_train, x_test, x_val, y_train, y_test, y_val = split_data(load_and_purge_data(), \"price\")\n",
    "cars_f = load_and_purge_data()\n",
    "val_col = cars_f[[\"price\"]]\n",
    "cars_f = cars_f.drop(\"price\", axis=1)\n",
    "x_train, x_test, y_train, y_test = data_splitter(cars_f, val_col)\n",
    "mdl = make_model(x_train)\n",
    "history = mdl.fit(x_train, y_train, batch_size=32, epochs=100, validation_data=(x_test, y_test))\n",
    "# results = mdl.evaluate(x_val, y_val, batch_size=128)\n",
    "print(\"test loss, test acc:\", history)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
